{"name":"etl-by-example","tagline":"","body":"ETL By Example\r\n=========\r\n\r\nThe purpose of this project is to provide a collaborative environment for learning how to perform \"Extract Transform Load\" (ETL) processes using Hadoop.\r\n\r\nThe hope is that through sample code and detailed explanations in the wiki, the learning process for data ETL will be simplified. We are encouraging others to contribute.\r\n\r\nPlease refer to the project wiki for further information (https://github.com/Lab41/etl-by-example/wiki)\r\n\r\nWhat the code does\r\n============\r\nThe actual code in this project ingests \"SampleRecords\" from a CSV file generated by the Generate class.  We read the files with a mapper, convert to Avro in the reducer, pivoting on a time field in each record.  When running via oozie, we then move the original files to an archive, and then move the converted files to a directory intended for querying.\r\n\r\n\r\nGetting Started\r\n========\r\n\r\n1. Clone the project\r\n2. mvn package\r\n3. create sample data Generator.java\r\n3. Run the project (Two ways)\r\n      - Via a driver ->  ./bin/run.sh\r\n      - Via oozie -> use workflow in src/main/workflow\r\n\r\nContributing\r\n========\r\n\r\nContributions are most welcome to both the wiki and the code.  To contribute, issue a pull request, make the changes, and we will merge it back into the trunk. \r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}